---
title: "응급의료 취약지 분석"
author: "[Golden Time](https://github.com/twg12/IntroToDataScience_5)"
date: "`r Sys.Date()`"
output:
  html_document: 
    toc: yes
    toc_float: true
    highlight: tango
    code_folding: show
    number_section: true
    self_contained: true
editor_options: 
  chunk_output_type: console
runtime: shiny
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r echo=FALSE, result='hide', message=FALSE}
mylocation = "C:\\Users\\YoonHoJeong\\Desktop\\Projects\\data_science_2020\\viz\\final"

setwd(mylocation)

library(knitr)
library(readr)
library(tidyverse)
library(skimr)
library(stringr)
library(recipes)
library(tidymodels)

library(httr)
library(XML)
library(xml2)
library(writexl)
library(tictoc)
```


# 국내 응급의료 취약지 선정의 현주소

["보건복지부는 최근 행정예고를 통해 ‘지역응급의료센터로 30분내 도달이 불가능하거나, 권역응급의료센터로 1시간 이내 도달이 불가능한 인구가 지역 내 30% 이상인 지역’을 응급의료취약지로 지정하도록 했다."](http://www.docdocdoc.co.kr/news/articleView.html?idxno=1038322)  

2017년에 지정되어 현재까지 이어져오고 있는 응급의료취약지 지정 기준은 특정 지역에서의 응급의료센터까지의 접근성을 기준으로 판단되고 있다.  

하지만 이러한 지정 기준은 응급 의료 상황 시에 적합한 수술 및 치료를 다할 수 있는지에 대한 **1)응급 의료 시설 인프라 점수**와, **2)해당 응급 의료 시설을 이용하는 실제 인구 수**를 반영하지 못하는 한계점을 갖는다.
따라서 우리는 각 지역의 응급의료시설에 대한 응급의료 시설 인프라 점수와 취약 계층을 반영한 응급 의료 취약지를 선정한다.


# 데이터 선정
응급의료 취약지를 선정하기 위한 요인들을 고려했다.  

### 접근성
  - 응급 상황 시 환자의 이송시간은 환자의 생존여부과 큰 상관 관계를 갖는다. 하지만 우리나라의 인허가된 의료시설을 살펴보면 병원은 3,881개로 이 가운데 3,194개가 도시지역에 집중되어 있다.
  
### 취약 인구 지수, 인구 밀도
  - 우리나라 고령인구 비율은 전체 인구 중 13.2%이나, 농어촌지역은 37.8%로 도시지역에 비해 고령화가 빠르게 진행 중에 있다(Statistics, 2015). 고령인구 사망자 가운데 응급처치가 필요한 심장질환에 의한 사망자는 2006년 14,906명에서 2016년 24,259명으로 약 63%가 증가하였으며, 1년에 약 6%씩 증가하고 있는 것으로 조사되었다(Statistics, 2017). 향후 2060년에는 고령인구가 인구 전
체에 40%를 육박할 것으로 추정되어(Beak et al., 2016), 심장질환에 취약한 고령인구 또한 증가할 것으로 예상되고 있다.

### 응급의료시설 점수
  - 뇌졸중, 심근경색 등 중증 심혈관질환자의 경우, 인근 응급시설로 이송된 후, 해당 응급의료시설에서의 의료 자원 부족으로 적절한 조치를 받지 못하는 경우가 발생한다. 접근성 뿐만 아니라 해당 응급의료시설의 인프라도 중요하다고 판단하였다.  


## Data source
접근성과 응급의료시설 점수를 계산하기 위한 데이터 수집은 [공공데이터포털 - 전국 응급의료기관 조회 서비스](https://www.data.go.kr/data/15000563/openapi.do)를 활용했다.

## Data Extraction
데이터는 공공 데이터 센터에서 제공하는 API를 통해서 호출.
데이터 로딩에 오랜 시간이 걸리기 때문에, xlsx파일로 저장하고,
만약 해당 데이터가 존재하지 않는다면 API를 호출해서 파일로 저장한다.

### 응급의료기관 기본 정보 조회 서비스

```{r result='hide', message=FALSE}

# 응급의료기관 기본정보 조회 서비스
url = "http://openapi2.e-gen.or.kr/openapi/service/rest/ErmctInfoInqireService/"

api_call_func1 <- function() {
  ## 응급실 실시간 가용병상정보 조회 1번 오퍼레이터
  
  operator = "getEmrrmRltmUsefulSckbdInfoInqire"
  Servicekey = "your_service_key"
  pageNo = "1"
  numOfRows = "99"
  
  result_table_1 = tibble()
  for (i in 1:10){
    queryParams = str_c("?serviceKey=", Servicekey, "&pageNo=", as.character(i), "&numOfRows=", "50")
    doc = xmlInternalTreeParse(str_c(url, operator, queryParams))
    rootNode = xmlRoot(doc)
    names = rootNode[[2]][['items']][['item']] %>%
      names()
    tmp_tbl = xmlToDataFrame(nodes = getNodeSet(rootNode, '//item')) %>%
      set_names(iconv(names, "UTF-8", "CP949") %>% unname()) %>%
      as_tibble()
    result_table_1 = result_table_1 %>% bind_rows(.,tmp_tbl)}
  
  which(result_table_1$dutyName == "의료법인명지의료재단명지병원")
  result_table_1[c(23, 391),] # 이름은 같지만 지역이 다른 명지병원이므로 인정
  # 응급의료기관 지정 병원 갯수가 대략 402개 나옵니다
  
  write_xlsx(result_table_1, "응급의료기관 기본정보 조회 서비스_1.xlsx")
  write_excel_csv(result_table_1, "result_0527_12_16.csv")
}

```


### 응급의료기관 목록정보 조회
```{r result='hide', message=FALSE}
## 응급의료기관 조회서비스 3번 오퍼레이터 - 좌표값 찾기

api_call_func2 <- function() {
  pageNo = "1"
  numOfRows = "99" # "&pageNo=", pageNo, "&numOfRows=", numOfRows
  operator = "getEgytListInfoInqire"
  
  result_table_3 = tibble()
  
  for (i in 1:402){
    QN = result_table_1[i,1]
    queryParams = str_c("?serviceKey=", Servicekey, "&QN=", QN)
    doc = xmlInternalTreeParse(str_c(url, operator, queryParams))
    rootNode = xmlRoot(doc)
    tmp_tbl_2 = xmlToDataFrame(nodes = getNodeSet(rootNode, '//items//hpid')) %>% as_tibble(.name_repair = "unique")
    tmp_tbl_3 = xmlToDataFrame(nodes = getNodeSet(rootNode, '//items//dutyName')) %>% as_tibble(.name_repair = "unique")
    tmp_tbl_4 = xmlToDataFrame(nodes = getNodeSet(rootNode, '//items//wgs84Lon')) %>% as_tibble(.name_repair = "unique")
    tmp_tbl_5 = xmlToDataFrame(nodes = getNodeSet(rootNode, '//items//wgs84Lat')) %>% as_tibble(.name_repair = "unique")
    tmp_tbl_2 = tmp_tbl_2 %>% bind_cols(.,tmp_tbl_3) %>% bind_cols(.,tmp_tbl_4) %>% bind_cols(.,tmp_tbl_5)
    result_table_3 = result_table_3 %>% bind_rows(.,tmp_tbl_2)}
  
  write_xlsx(result_table_3, "응급의료기관 목록정보 조회 서비스_3.xlsx")
}


```

### 중증질환자 수용가능 정보 오퍼레이터
```{r eval=FALSE, error= FALSE, message=FALSE}
# (2) 중증질환자 수용가능 정보 오퍼레이터
api_call_func3 <- function() {
  operator = "getSrsillDissAceptncPosblInfoInqire"
  result_table_2 = tibble()
  
  for (i in 1:40){
    queryParams = str_c("?serviceKey=", Servicekey, "&pageNo=", as.character(i), "&numOfRows=", "14")
    doc = xmlInternalTreeParse(str_c(url, operator, queryParams))
    rootNode = xmlRoot(doc)
    names = rootNode[[2]][['items']][['item']] %>%
      names()
    tmp_tbl_2 = xmlToDataFrame(nodes = getNodeSet(rootNode, '//items')) %>%
      as_tibble(.name_repair = "unique")
    result_table_2 = result_table_2 %>% bind_rows(.,tmp_tbl_2)}
  
  result_table_2.df = tibble()
  for (i in 1:23){
    for (j in 1:14){
      result_table_2.df[j+14*(i-1),1] = str_extract(result_table_2[i,j], "[가-힣]+")
      result_table_2.df[j+14*(i-1),2] = str_extract(result_table_2[i,j], "[a-zA-Z][0-9]+")
      result_table_2.df[j+14*(i-1),3] = substr(str_extract(result_table_2[i,j], "[a-zA-Z]{12}"), 1, 1)
      result_table_2.df[j+14*(i-1),4] = substr(str_extract(result_table_2[i,j], "[a-zA-Z]{12}"), 2, 2)
      result_table_2.df[j+14*(i-1),5] = substr(str_extract(result_table_2[i,j], "[a-zA-Z]{12}"), 3, 3)
      result_table_2.df[j+14*(i-1),6] = substr(str_extract(result_table_2[i,j], "[a-zA-Z]{12}"), 4, 4)
      result_table_2.df[j+14*(i-1),7] = substr(str_extract(result_table_2[i,j], "[a-zA-Z]{12}"), 5, 5)
      result_table_2.df[j+14*(i-1),8] = substr(str_extract(result_table_2[i,j], "[a-zA-Z]{12}"), 6, 6)
      result_table_2.df[j+14*(i-1),9] = substr(str_extract(result_table_2[i,j], "[a-zA-Z]{12}"), 7, 7)
      result_table_2.df[j+14*(i-1),10] = substr(str_extract(result_table_2[i,j], "[a-zA-Z]{12}"), 8, 8)
      result_table_2.df[j+14*(i-1),11] = substr(str_extract(result_table_2[i,j], "[a-zA-Z]{12}"), 9, 9)
      result_table_2.df[j+14*(i-1),12] = substr(str_extract(result_table_2[i,j], "[a-zA-Z]{12}"), 10, 10)
      result_table_2.df[j+14*(i-1),13] = substr(str_extract(result_table_2[i,j], "[a-zA-Z]{12}"), 11, 11)
      result_table_2.df[j+14*(i-1),14] = substr(str_extract(result_table_2[i,j], "[a-zA-Z]{12}"), 12, 12)}}
  result_table_2.df = result_table_2.df[1:313,]
  
  write_xlsx(result_table_2.df, "중증질환자 수용가능 정보_2.xlsx")

}
```

### 응급의료기관 기본정보 조회 오퍼레이션
```{r eval=FALSE, error=FALSE, message=FALSE}
## (5) 응급의료기관 기본정보 조회 오퍼레이션
api_call_func4 <- function() {

  operator = "getEgytBassInfoInqire"
  result_table_5 = tibble()
  
  for (i in 1:2000){
    tic()
    queryParams = str_c("?serviceKey=", Servicekey, "&pageNo=", as.character(i), "&numOfRows=", "50")
    doc = xmlInternalTreeParse(str_c(url, operator, queryParams))
    rootNode = xmlRoot(doc)
    tmp_tbl_2 = xmlToDataFrame(getNodeSet(rootNode, "//item")) %>% as_tibble()
    result_table_5 = result_table_5 %>% bind_rows(.,tmp_tbl_2)
    toc()}
  write_xlsx(result_table_5, "응급의료기관 기본정보 조회_5_1.xlsx")
  
  table(duplicated(result_table_5$dutyName))
}
```

### 외상센터 기본정보 조회 오퍼레이션
```{r eval=FALSE, error=FALSE, message=FALSE}
## (8) 외상센터 기본정보 조회 오퍼레이션

api_call_func5 <- function() {
  operator = "getStrmBassInfoInqire"
  result_table_8 = tibble()
  for (i in 1:10){
    queryParams = str_c("?serviceKey=", Servicekey, "&pageNo=", as.character(i), "&numOfRows=", "50")
    doc = xmlInternalTreeParse(str_c(url, operator, queryParams))
    rootNode = xmlRoot(doc)
    tmp_tbl_3 = xmlToDataFrame(nodes = getNodeSet(rootNode, '//item')) %>% as_tibble()
    result_table_8 = result_table_8 %>% bind_rows(.,tmp_tbl_3)}
  
  write_xlsx(result_table_8, "외상센터 기본정보 조회_8.xlsx")
}
```

# 접근성 계산
- 대한민국 지도에서 읍, 면, 동 단위로 각 지점에서 특정 거리 내에 있는 응급 의료 시설 거리를 합산한다. 그 중 30분 내에 도달 가능한 병원이 없는 경우 취약지역으로 선정한다. 정부는 ‘공공보건의료에 관한 법률’ 제12조 제2항 및 제3항에 의해서 응급의료분야 의료취약지를 선정하고 있는데, 구체적인 기준은 다음과 같다.

#### 지역내 30% 이상의 인구가 지역응급의료센터로 30분 이내 도달이 불가능하거나 권역응급의료센터로 1시간 이내 도달이 불가능한 경우

따라서 30분 이내 도달 가능한 병원이 없는 지역을 일차적으로 응급의료취약지역으로 설정하고 시각화에 반영한다. 세부 사항은 추후 classification 과정에서 감안할 것이다.

# 의료시설 인프라 점수 도출
- API를 통해 추출한 데이터 영역에서 특정 변수들을 선택해 해당 응급의료시설에 대한 점수를 구성한다.  

선택한 변수는 아래와 같다.

1. hv2 : 내과중환자실
1. hv3 : 외과중환자실 
1. hv6 : 신경외과중환자실   
1. hv9 : 외상중환자
1. hvec : 응급실
1. hvgc : 입원실
1. hvoc : 수술실
1. hv10 : VENTI(소아)
1. hv11 : 인큐베이터(보육기)   
1. hv5 : 신경과입원실
1. hv7 : 약물중환자
1. hvctayn : CT가용(가/부)
1. hvmriayn : MRI가용(가/부)
1. hvventiayn : 인공호흡기가용(가/부)
1. mkioskty1 : 뇌출혈수술
1. mkioskty2 : 뇌경색의재관류
1. mkioskty3 : 심근경색의재관류
1. mkioskty4 : 복부손상의수술
1. mkioskty5 : 사지접합의수술
1. mkioskty6 : 응급내시경
1. mkioskty7 : 응급투석
1. mkioskty8 : 조산산모
1. mkioskty10 : 신생아
1. mkioskty11 : 중증화상

```{r include=FALSE}
library(readr)
library(tidyverse)
library(skimr)
library(stringr)
library(recipes)
library(tidymodels)
```


## EDA
### API를 통해 저장한 csv파일 불러오기
2개의 파일은 다음과 같다.

1. '응급의료기관 기본정보 조회 서비스_1.csv'
2. '중증질환자 수용가능 정보_2.csv'

```{r read-data, include=FALSE}
table_1 <- read_csv('응급의료기관 기본정보 조회 서비스_1.csv')
table_2 <- read_csv('중증질환자 수용가능 정보_2.csv')
```

### 표 합치기
dplyr 패키지의 inner_join함수를 통해 불러온 두개의 표를 합친다. 합칠 때 기준이 되는 것은 병원의 ID('hpid')이다.

```{r}
hpdata <- inner_join(table_1, table_2, by='hpid')
```

### 변수선택

응급의료에 영향을 주는 변수를 선택했다. 선택에서 제외된 변수는 '응급실 당직 직통연락처', '외과입원실', '신결과입원실',
'약물중환자', '화상중환자', '외상중환자', '소아당직 직통연락처', '입력일시', '신경중환자', '일반중환자', '신생중환자', '흉부중환자', '정신질환자 수용가능여부', '응급실 지킴이 유무'이다.

```{r}
hpdata <- hpdata %>%
  select(dutyName.x, starts_with('h'), starts_with('mk'))%>%
  select(-hv1, -hv12, -hvidate, -hvcc, -hvncc, -hvccc, -hvicc, -mkioskty25, -mkioskty9)
#glimpse(hpdata)
#str(hpdata)
```

### 변수 별로 변수가 취하는 값의 개수

변수가 취할 수 있는 값의 개수를 확인하여 변수의 특성을 확인하였다.
```{r}
nuniq <- c()
for(i in 1:length(colnames(hpdata))) {
  nuniq[i] <- hpdata[,i] %>%
  n_distinct()
}
nuniq
```

### 분산이 0인 변수를 제거
```{r}
hpdata <- hpdata[,nuniq!=1]
```
```{r}
#str(hpdata)
nuniq <- c()
for(i in 1:length(colnames(hpdata))) {
  nuniq[i] <- hpdata[,i] %>%
  n_distinct()
}
nuniq
```

### 가변수 분리

0과 1, 또는 Yes와 No로 나뉘는 가변수들을 따로 분리한다.
```{r}
hpdata_f <- hpdata[,nuniq<=3]
hpdata_n <- hpdata[,nuniq>3]
```


### 가변수들이 0과 1로 통일
```{r}
hpdata_f <- hpdata_f %>%
  mutate_all(funs(recode(., 'N1'=0L, '0'=0L, 'N'=0L, '1'=1L, 'Y'=1L, .default=1L)))
#str(hpdata_f)
```

### 분리했던 변수들을 다시 합친다. 
```{r}
hpdata <- bind_cols(hpdata_n, hpdata_f)
glimpse(hpdata)
```

### 각변수를 평균=0, 분산=1로 정규화 한다.
```{r}
hpdata_z <- hpdata %>%
  mutate_each_(funs(scale), vars=colnames(hpdata)[3:length(colnames(hpdata))])
#head(hpdata_z[,3:32])
```

### 공선성 진단
```{r}
multi <- lm(1:nrow(hpdata_z)~hv2+hv3+hv6+hvec+hvgc+hvoc+hv10+hv11+hvctayn+hvmriayn+hvventiayn+mkioskty1+mkioskty2+mkioskty3+mkioskty4+ mkioskty5+mkioskty6+mkioskty7+mkioskty8+mkioskty10+mkioskty11, data = hpdata_z, na.action = na.omit)
#alias(multi)
car::vif(multi)
```
공선성이 진단되지 않았기 때문에 주성분분석을 통해 구성된 점수를 해석하는 것이 가능하다.


## 주성분 분석, PCA
병원 점수 축을 생성하기 위하여 앞서 추출한 변수들을 통해 PCA 기법을 활용했다.


### 주성분 분석
```{r}
hp_without_id <- hpdata_z[,3:length(colnames(hpdata_z))] %>%
    as.matrix()
hp_pca <- prcomp(hp_without_id)
hp_pca[[1]] # 각 축들의 표준편차
```
```{r}
hp_pca[[2]][,1:3] # 1~3번째 축에서 나타나는 변수별 가중치
```
첫번째 축을 보면 모든 변수들의 가중치가 같은 방향으로 부여되는 것을 확인할 수 있다. 
\[y=\beta_1X_1+\beta_2X_2+\beta_3X_3+ ... \beta_{21}X_{21}\]이고, 각 \(\beta\)들은 음의 값으로 나왔기 때문에, -y에 적절한 상수를 곱하고 더하여 병원 점수를 구성할 수 있다. 

### 설명된 분산의 양: \(R^2\)
첫번째 축은 전체 분산의 28.9%를 설명한다. 그 다음 축들이 설명하는 분산의 양은 10.2%, 6.3%, ... 로 첫번째 축에 비해 급격하게 줄어드는 모습을 볼 수 있다. 
```{r}
summary(hp_pca)
```
설명된 분산의 양을 scree plot을 통해 나타내면 다음과 같다.
```{r}
screeplot(hp_pca, col = "blue", type = "lines", pch = 21, main="Scree Plot")
```


### 첫번째 축을 활용하여 병원 점수 구성하기
##### 점수의 평균은 100, 표준편차는 20이다.
```{r}
hp_pc1 <- predict(hp_pca)[,1] # 첫번째 축에 각 데이터를 정사영하여 병원점수를 구성한다.
hp_score <- (100-20*scale(hp_pc1))
hospital_score <- hpdata %>%
  select(dutyName.x,hpid)%>%
  mutate(score=hp_score)     # 병원이름, 병원ID, 병원점수를 선택하여 'hospital_score'라는 표를 만든다. 
skim(hospital_score)
```


### 병원점수 시각화
```{r}
library(ggplot2)
ggplot(hospital_score, aes(x=score))+
  geom_histogram(fill='sky blue', binwidth = 3)
```

### 병원점수 .csv 파일로 내보내기
```{r, include=FALSE}
write.csv(hospital_score, file = 'hospital_score')
```

## 시각화
```{r, include=FALSE}

library(readxl)

result_table_3 <- read_excel("응급의료기관 목록정보 조회 서비스_3.xlsx")


# write.csv(hospital_score_raw_bin, file = 'hospital_score_raw_binary.csv')
```

```{r, include=FALSE}
# 인구 밀도에 따른 국내 지도 시각화

library(sp)
library(rgdal)

TL = readOGR(mylocation, "LI") # 첫 인자에 파일 위치, 두번째 인자에 파일명

# Option1 불러온 공간 데이터 내에서 좌표계 방식 변환  (UTM-K -> WGS84)

# from.crs = TL@proj4string
to_crs = CRS("+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs")
TL_1 = spTransform(TL, to_crs)

tmp_1 = TL_1@data

for (i in 1:nrow(tmp_1)){
  tmp_1$x_coord[i] = parse_number(as.character(TL_1@polygons[[i]]@labpt)[1])
  tmp_1$y_coord[i] = parse_number(as.character(TL_1@polygons[[i]]@labpt)[2])
}

# Haversine 공식으로 거리 계산

library(geosphere)

dist = list()
for (i in 1:nrow(tmp_1)){
dist[[i]] = c(tmp_1$x_coord[i], tmp_1$y_coord[i])
}

medi = list()
for (i in 1:nrow(result_table_3)){
  medi[[i]] = c(parse_number(result_table_3$text2[i]), parse_number(result_table_3$text3[i]))
}

# 거리 계산하여 10km 이내에 도달 가능한 응급의료기관 수 계산

tmp_1$num = 0
for (i in 1:length(dist)){
  for (j in 1:length(medi)){
  ifelse(distHaversine(dist[[i]], medi[[j]])<10000, tmp_1$num[i] <- tmp_1$num[i]+1, next)
  }
}
```

```{r, include=FALSE}
write.csv(tmp_1, "Haversine_list.csv")
```

```{r, include=FALSE}
library(leaflet)

TL_1 = sp::merge(TL_1, tmp_1)

# Shiny Dashboard 활용

library(shiny)
library(shinydashboard)

ui <- fluidPage(
  mainPanel( 
leafletOutput(outputId = "mymap")))

server <- function(input, output, session) {
  pal2 = colorNumeric("viridis", TL_1@data$num, reverse=TRUE)
  
  output$mymap = renderLeaflet({leaflet(TL_1) %>%
    setView(lng=127.7669,lat=35.90776, zoom=7) %>%
    addProviderTiles('CartoDB.Positron') %>%
    addPolygons(color='#444444', weight=0.5, opacity = 1.0, fillOpacity = 0.5, fillColor=~pal2(num))
  })
}

shinyApp(ui, server)
```

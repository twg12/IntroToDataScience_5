---
title: "Prototype"
author: "golden-time"
date: '2020-6-17'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

mylocation = "C:/Users/Byeongjun Cho/Desktop/2020-1/IntroToDataScience_5/data"
setwd(mylocation)

library(tidyverse)
library(httr)
library(XML)
library(xml2)
library(writexl)
library(tictoc)
library(sp)
library(rgdal)
library(geosphere)
library(shiny)
library(shinydashboard)
library(leaflet)
library(readr)
library(skimr)
library(stringr)
library(recipes)
library(tidymodels)
```

### API Calling

```{r, echo=FALSE}
url = "http://openapi2.e-gen.or.kr/openapi/service/rest/ErmctInfoInqireService/"

## 응급실 실시간 가용병상정보 조회 1번 오퍼레이터

operator = "getEmrrmRltmUsefulSckbdInfoInqire"
Servicekey = ""
pageNo = "1"
numOfRows = "99"

result_table_1 = tibble()
for (i in 1:10){
    queryParams = str_c("?serviceKey=", Servicekey, "&pageNo=", as.character(i), "&numOfRows=", "50")
    doc = xmlInternalTreeParse(str_c(url, operator, queryParams))
    rootNode = xmlRoot(doc)
    names = rootNode[[2]][['items']][['item']] %>%
        names()
    tmp_tbl = xmlToDataFrame(nodes = getNodeSet(rootNode, '//item')) %>%
        set_names(iconv(names, "UTF-8", "CP949") %>% unname()) %>%
        as_tibble()
    result_table_1 = result_table_1 %>% bind_rows(.,tmp_tbl)}

pageNo = "1"
numOfRows = "99" # "&pageNo=", pageNo, "&numOfRows=", numOfRows
operator = "getEgytListInfoInqire"

result_table_3 = tibble()
for (i in 1:402){
    QN = result_table_1[i,1]
    queryParams = str_c("?serviceKey=", Servicekey, "&QN=", QN)
    doc = xmlInternalTreeParse(str_c(url, operator, queryParams))
    rootNode = xmlRoot(doc)
    tmp_tbl_2 = xmlToDataFrame(nodes = getNodeSet(rootNode, '//items//hpid')) %>% as_tibble(.name_repair = "unique")
    tmp_tbl_3 = xmlToDataFrame(nodes = getNodeSet(rootNode, '//items//dutyName')) %>% as_tibble(.name_repair = "unique")
    tmp_tbl_4 = xmlToDataFrame(nodes = getNodeSet(rootNode, '//items//wgs84Lon')) %>% as_tibble(.name_repair = "unique")
    tmp_tbl_5 = xmlToDataFrame(nodes = getNodeSet(rootNode, '//items//wgs84Lat')) %>% as_tibble(.name_repair = "unique")
    tmp_tbl_2 = tmp_tbl_2 %>% bind_cols(.,tmp_tbl_3) %>% bind_cols(.,tmp_tbl_4) %>% bind_cols(.,tmp_tbl_5)
    result_table_3 = result_table_3 %>% bind_rows(.,tmp_tbl_2)}
```

# 1. EDA

### reading csv file

```{r data, include=FALSE}
table_1 <- read_csv('응급의료기관 기본정보 조회 서비스_1.csv')
table_2 <- read_csv('중증질환자 수용가능 정보_2.csv')
```

### merging plots
```{r}
hpdata <- inner_join(table_1, table_2, by='hpid')
```

### selecting variables
```{r}
hpdata <- hpdata %>%
  select(dutyName.x, starts_with('h'), starts_with('mk'))%>%
  select(-hv1, -hv12, -hvidate, -hvcc, -hvncc, -hvccc, -hvicc, -mkioskty25, -mkioskty9)
#glimpse(hpdata)
#str(hpdata)
```

### length of unique values in each variable
```{r}
nuniq <- c()
for(i in 1:length(colnames(hpdata))) {
  nuniq[i] <- hpdata[,i] %>%
  n_distinct()
}
nuniq
```

### remove columns with zero variance
```{r}
hpdata <- hpdata[,nuniq!=1]
```
```{r}
#str(hpdata)
nuniq <- c()
for(i in 1:length(colnames(hpdata))) {
  nuniq[i] <- hpdata[,i] %>%
  n_distinct()
}
nuniq
```

### devide table
```{r}
hpdata_f <- hpdata[,nuniq<=3]
hpdata_n <- hpdata[,nuniq>3]
```



### recoding
```{r}
hpdata_f <- hpdata_f %>%
  mutate_all(funs(recode(., 'N1'=0L, '0'=0L, 'N'=0L, '1'=1L, 'Y'=1L, .default=1L)))
#str(hpdata_f)
```

### merge again
```{r}
hpdata <- bind_cols(hpdata_n, hpdata_f)
glimpse(hpdata)
```

### centering and scaling
```{r}
hpdata_z <- hpdata %>%
  mutate_each_(funs(scale), vars=colnames(hpdata)[3:length(colnames(hpdata))])
#head(hpdata_z[,3:32])
```


# 2. PCA

### Principal Component Analysis
```{r}
hp_without_id <- hpdata_z[,3:length(colnames(hpdata_z))] %>%
    as.matrix()
hp_pca <- prcomp(hp_without_id)
hp_pca[[1]]
hp_pca[[2]][,1:3]
```


### variance explained: \(R^2\)
First conponent explains 25% of the total variance.
```{r}
summary(hp_pca)
```


### scree plot
```{r}
screeplot(hp_pca, main = "", col = "blue", type = "lines", pch = 21)
```


### hospital score
```{r}
hp_pc1 <- predict(hp_pca)[,1]
hp_score <- (100-20*scale(hp_pc1))
hospital_score <- hpdata %>%
  select(dutyName.x,hpid)%>%
  mutate(score=hp_score)
skim(hospital_score)
```


### plotting hospital scores
```{r}
library(ggplot2)
plot_score <- ggplot(hospital_score, aes(x=score))+
  geom_histogram(fill='sky blue', binwidth = 10)
plot_score
```

### exporting dataset
```{r}
write.csv(hospital_score, file = 'hospital_score')
```

### To Do 
* Exploratory Data Analysis
* Multicolinearity
* Variable selection
* Interpretation of each PC(constructing scores other than current hospital score)
  
### second component
```{r}
secondComponent <- hp_pca[[2]][,2]
as.matrix(secondComponent[order(secondComponent)])
```

### Multicolinearity, VIF
```{r}
#cor(hpdata_z[,-c(1,2)])
#pairs(hpdata_z[,-c(1,2)])
#pairs(hpdata_z[,3:9])
```

### merging data with hospital_score
```{r}
table_1 <- read_csv('응급의료기관 기본정보 조회 서비스_1.csv')
table_2 <- read_csv('중증질환자 수용가능 정보_2.csv')
hpdata_transient <- inner_join(table_1, table_2, by='hpid')
hpdata_full <- left_join(hpdata_transient, hospital_score, by='hpid')
write.csv(hpdata_full, file = 'hospital_score_fulldata.csv')
```

# 3. Constructing Valid Scores for hospitals in case of emergency

* Scores should indicate *the overall reliability* of hospitals in case of emergency, not indicating some other criteria such as the *size of the hospital*, and *expertise of doctors*, etc..
* Therefore, it is of primary interest whether there are emergency rooms available for immediately accomodating emergency patients. And thus, some ways to giving weight to the availability of emergency rooms has to be considered.
* The first way is to merge the raw data of the availability with overall hospital score, and the second is to merge binary data of the availability with overall hospital score.

### overall hospital score without emergency room
```{r}
hpdata_z_without_er <- hpdata_z %>%
  select(-dutyName.x, -hpid, -hvec) %>%
    as.matrix()
hp_pca_overall <- prcomp(hpdata_z_without_er)
hp_pca_overall[[1]]
hp_pca_overall[[2]][,1:3]
hp_pc1_overall <- predict(hp_pca_overall)[,1]
hp_score_overall <- (100-20*scale(hp_pc1_overall))
```

### Constructing Score using raw data
```{r}
hpdata_raw <- hpdata_z %>%
  select(dutyName.x, hpid, hvec) %>%
  mutate(score= scale(hp_score_overall))
hp_pca_raw <- prcomp(hpdata_raw[,3:4])
hp_pca_raw[[1]]
hp_pca_raw[[2]]
summary(hp_pca_raw)
hp_pc1_raw <- predict(hp_pca_raw)[,1]
hp_score_raw <- (100-20*scale(hp_pc1_raw))
```

### Constructing Score using binary data
```{r}
hpdata_binary <- hpdata_raw %>%
  mutate(hvec = ifelse(
    hvec >= 1, 1, 0
  ))
unique(hpdata_binary$hvec)
hp_pca_binary <- prcomp(hpdata_binary[,3:4])
hp_pca_binary[[1]]
hp_pca_binary[[2]]
summary(hp_pca_binary)
hp_pc1_binary <- predict(hp_pca_binary)[,1]
hp_score_binary <- (100-20*scale(hp_pc1_binary))
```

### Importing criterion for checking criterion validity
```{r}
criterion <- read_csv('hospital_score_fulldata_criterion.csv') %>%
  select(hpid, criterion)
hospital_score_raw_bin <- hpdata %>%
  select(dutyName.x,hpid)%>%
  mutate(score_overall=hp_score_overall,
         score_raw=hp_score_raw,
         score_binary=hp_score_binary) %>%
  full_join(., criterion, by= 'hpid')
unique(hospital_score_raw_bin$criterion)
hospital_score_raw_bin <- hospital_score_raw_bin %>%
  mutate(criterion=recode(criterion, '1'=1L, '2'=2L, '3'=3L, .default=NA_integer_))
str(hospital_score_raw_bin)
```

### Checking criterion validity
```{r}
cor(hospital_score_raw_bin[,3:6], use= 'pairwise.complete.obs')
hospital_score_raw_bin %>% 
  drop_na(criterion)%>%
  ggplot(aes(as.factor(criterion),score_overall))+
  geom_point(position = 'jitter')+
  labs(x='Criterion')

hospital_score_raw_bin %>% 
  drop_na(criterion)%>%
  ggplot(aes(as.factor(criterion),score_raw))+
  geom_point(position = 'jitter')+
  labs(x='Criterion')

hospital_score_raw_bin %>% 
  drop_na(criterion)%>%
  ggplot(aes(as.factor(criterion),score_binary))+
  geom_point(position = 'jitter')+
  labs(x='Criterion')
```
```{r}
a <- inner_join(hospital_score_raw_bin, select(hpdata, hpid, hvec), by='hpid')
cor(a$criterion, a$hvec, use='complete.obs')

a %>% 
  drop_na(criterion)%>%
  ggplot(aes(as.factor(criterion),hvec))+
  geom_point(position = 'jitter')+
  labs(x='Criterion')
```
  
### Exporting data
```{r, include=FALSE}
write.csv(hospital_score_raw_bin, file = 'hospital_score_raw_binary.csv')
```

#### Importing Data 

```{r, eval=FALSE, echo=FALSE}
hospital_score = read.csv("hospital_score_2.csv") %>% as_tibble()
hospital_score = hospital_score %>% 
    select(hpid, score) %>%
    mutate(score = score/100)
result_table_3 = result_table_3 %>% 
    rename(hpid = "text") %>%
    full_join(hospital_score, by = "hpid")
result_table_3 = result_table_3 %>% mutate(score = replace_na(score, 1))
result_table_3 = result_table_3 %>% drop_na()
```

#### Spatial Data pre-processing(UTM-8 -> WGS84)

```{r, echo=FALSE}
library(sp)
library(rgdal)

TL = readOGR(mylocation, "TL_SCCO_LI") # 첫 인자에 파일 위치, 두번째 인자에 파일명

# 불러온 공간 데이터 내에서 좌표계 방식 변환  (UTM-K -> WGS84)

# from.crs = TL@proj4string
to_crs = CRS("+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs")
TL_1 = spTransform(TL, to_crs)

tmp_1 = TL_1@data

for (i in 1:nrow(tmp_1)){
  tmp_1$x_coord[i] = parse_number(as.character(TL_1@polygons[[i]]@labpt)[1])
  tmp_1$y_coord[i] = parse_number(as.character(TL_1@polygons[[i]]@labpt)[2])
}
```

#### Haversine Calculation

```{r}
# Haversine 공식으로 거리 계산

library(geosphere)

dist = list()
for (i in 1:nrow(tmp_1)){
dist[[i]] = c(tmp_1$x_coord[i], tmp_1$y_coord[i])
}

medi = list()
for (i in 1:nrow(result_table_3)){
  medi[[i]] = c(parse_number(result_table_3$text2[i]), parse_number(result_table_3$text3[i]))
}

# 거리 계산하여 30km 이내에 도달 가능한 응급의료기관 수 계산

tmp_1$num = 0
for (i in 1:length(dist)){
  for (j in 1:length(medi)){
  ifelse(distHaversine(dist[[i]], medi[[j]])<30000, tmp_1$num[i] <- tmp_1$num[i]+1, next)
  }
}

tmp_1$score_num = 0
for (i in 1:length(dist)){
  for (j in 1:length(medi)){
    ifelse(distHaversine(dist[[i]], medi[[j]])<30000, 
           tmp_1$score_num[i] <- tmp_1$score_num[i]+result_table_3$score[j], 
           next)
  }
}
TL_1 = sp::merge(TL_1, tmp_1)

write.csv(tmp_1, "Haversine_list.csv")
```

#### Leaflet Visualization (prototype)

```{r, echo=FALSE}
mainPanel(leafletOutput(outputId = "mymap", height = "900px", width = "125%"))

bins = c(0, 4.476, 13.739, 32.531, 40.033, 84, Inf)
pal = colorBin("YlGnBu", domain = TL_1@data$score_num, bins = bins)

renderLeaflet({
    leaflet(TL_1_simple) %>%
        setView(lng=127.7669,lat=35.90776, zoom=7.5) %>%
        addProviderTiles('CartoDB.Positron') %>%
        addPolygons(color='#444444', 
                    weight=2, opacity = 1.0, fillOpacity = 0.5, 
                    fillColor=~pal(score_num)) %>%
        addLegend(pal = pal, values = ~score_num, opacity = 0.7, title = NULL,
                  position = "bottomright")})
```